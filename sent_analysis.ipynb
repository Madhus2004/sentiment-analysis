{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2004b2",
   "metadata": {},
   "source": [
    "Kindle Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7d80acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bed163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Admin\\Desktop\\Madhu\\udemyproject\\NLP practice\\kindle\\archive (8)\\all_kindle_review .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "49ded237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2cab8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['reviewText','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a71ee5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "00e04928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                               reviewText  rating\n",
       "0      Jace Rankin may be short, but he's nothing to ...       3\n",
       "1      Great short read.  I didn't want to put it dow...       5\n",
       "2      I'll start by saying this is the first of four...       3\n",
       "3      Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4      I did not expect this type of book to be in li...       4\n",
       "...                                                  ...     ...\n",
       "11995  Valentine cupid is a vampire- Jena and Ian ano...       4\n",
       "11996  I have read all seven books in this series. Ap...       5\n",
       "11997  This book really just wasn't my cuppa.  The si...       3\n",
       "11998  tried to use it to charge my kindle, it didn't...       1\n",
       "11999  Taking Instruction is a look into the often hi...       3\n",
       "\n",
       "[12000 rows x 2 columns]>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b00db30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0ed0347f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0d766e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af619a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e566e",
   "metadata": {},
   "source": [
    "preprocess and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "07808fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive review is 1 and negative is 0\n",
    "df['rating']=df['rating'].apply(lambda x: 0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1d334f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       1\n",
       "1  Great short read.  I didn't want to put it dow...       1\n",
       "2  I'll start by saying this is the first of four...       1\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       1\n",
       "4  I did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5a4b4bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a4231efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26463eb7",
   "metadata": {},
   "source": [
    "1. Lower all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "670a3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText']=df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed0b5d",
   "metadata": {},
   "source": [
    "2. Remove special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e50a5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\admin\\desktop\\madhu\\udemyproject\\nlp practice\\venv\\lib\\site-packages (5.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "98c702cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4.0\n"
     ]
    }
   ],
   "source": [
    "import lxml\n",
    "print(lxml.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "063077ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords.words('english')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4f032599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText']=df['reviewText'].apply(lambda x: re.sub('[^a-z A-Z0-9]+','',x))\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y not in \n",
    "                                                            stopwords.words('english')]))\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[w_-]+)+))([w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','',str(x)))\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ea42e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short hes nothing mess man hau...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four books wasnt expect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carries pocketbooks inst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short hes nothing mess man hau...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four books wasnt expect...       1\n",
       "3  aggie angela lansbury carries pocketbooks inst...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8547af7",
   "metadata": {},
   "source": [
    "Lemmatization - Wordnetlemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f7e3a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f98ab57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e829bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem(text):\n",
    "    return \" \".join([lm.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7b015db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText']=df['reviewText'].apply(lambda x: lem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "37d8700d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short he nothing mess man haul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four book wasnt expecti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carry pocketbook instead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short he nothing mess man haul...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four book wasnt expecti...       1\n",
       "3  aggie angela lansbury carry pocketbook instead...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c01b43",
   "metadata": {},
   "source": [
    "Train Test split and model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "534efb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['reviewText'],df['rating'],test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79b546",
   "metadata": {},
   "source": [
    "BOW,TFIDF,Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "608ef003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer()\n",
    "X_train_bow=bow.fit_transform(X_train).toarray()\n",
    "X_test_bow=bow.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c4098d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "13ad7993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf=tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a94e11",
   "metadata": {},
   "source": [
    "GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5f60811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_bow=GaussianNB().fit(X_train_bow,y_train)\n",
    "nb_tfidf=GaussianNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4bb99045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "63ff8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow=nb_bow.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "33bda5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf=nb_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7b48cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy 0.5783333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW accuracy\",accuracy_score(y_test,y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa165a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[522, 277],\n",
       "       [735, 866]], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a5e97803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf accuracy 0.57625\n"
     ]
    }
   ],
   "source": [
    "print(\"Tfidf accuracy\",accuracy_score(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cdc726c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report for BOW               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.65      0.51       799\n",
      "           1       0.76      0.54      0.63      1601\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.59      0.60      0.57      2400\n",
      "weighted avg       0.64      0.58      0.59      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report for BOW\",classification_report(y_test,y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2ba781df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report for Tfidf               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.63      0.50       799\n",
      "           1       0.75      0.55      0.63      1601\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.58      0.59      0.57      2400\n",
      "weighted avg       0.64      0.58      0.59      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report for Tfidf\",classification_report(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66f6d5",
   "metadata": {},
   "source": [
    "Word2vec implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1f764e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_wv,X_test_wv,y_train_wv,y_test_wv=train_test_split(df['reviewText'],df['rating'],test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be98d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7a05b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "56a2f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jace rankin may short he nothing mess man haul...\n",
       "1        great short read didnt want put read one sitti...\n",
       "2        ill start saying first four book wasnt expecti...\n",
       "3        aggie angela lansbury carry pocketbook instead...\n",
       "4        expect type book library pleased find price right\n",
       "                               ...                        \n",
       "11995    valentine cupid vampire jena ian another vampi...\n",
       "11996    read seven book series apocalypticadventure on...\n",
       "11997    book really wasnt cuppa situation man capturin...\n",
       "11998    tried use charge kindle didnt even register ch...\n",
       "11999    taking instruction look often hidden world sex...\n",
       "Name: reviewText, Length: 12000, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_train=X_train_wv.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0937f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=gensim.models.Word2Vec(sent_train,vector_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4e92db69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book',\n",
       " 'story',\n",
       " 'read',\n",
       " 'one',\n",
       " 'character',\n",
       " 'like',\n",
       " 'good',\n",
       " 'would',\n",
       " 'really',\n",
       " 'love',\n",
       " 'get',\n",
       " 'time',\n",
       " 'author',\n",
       " 'series',\n",
       " 'reading',\n",
       " 'much',\n",
       " 'first',\n",
       " 'well',\n",
       " 'even',\n",
       " 'didnt',\n",
       " 'short',\n",
       " 'know',\n",
       " 'could',\n",
       " 'great',\n",
       " 'way',\n",
       " 'make',\n",
       " 'sex',\n",
       " 'little',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'thing',\n",
       " 'two',\n",
       " 'think',\n",
       " 'plot',\n",
       " 'find',\n",
       " 'also',\n",
       " 'end',\n",
       " 'romance',\n",
       " 'im',\n",
       " 'life',\n",
       " 'see',\n",
       " 'enjoyed',\n",
       " 'go',\n",
       " 'scene',\n",
       " 'never',\n",
       " 'take',\n",
       " 'lot',\n",
       " 'say',\n",
       " 'woman',\n",
       " 'written',\n",
       " 'many',\n",
       " 'work',\n",
       " 'kindle',\n",
       " 'thought',\n",
       " 'give',\n",
       " 'liked',\n",
       " 'year',\n",
       " 'found',\n",
       " 'bit',\n",
       " 'going',\n",
       " 'interesting',\n",
       " 'writing',\n",
       " 'loved',\n",
       " 'come',\n",
       " 'better',\n",
       " 'novel',\n",
       " 'got',\n",
       " 'another',\n",
       " 'back',\n",
       " 'still',\n",
       " 'feel',\n",
       " 'man',\n",
       " 'hot',\n",
       " 'reader',\n",
       " 'made',\n",
       " 'enough',\n",
       " 'something',\n",
       " 'though',\n",
       " 'people',\n",
       " 'review',\n",
       " 'star',\n",
       " 'part',\n",
       " 'page',\n",
       " 'need',\n",
       " 'friend',\n",
       " 'cant',\n",
       " 'keep',\n",
       " 'bad',\n",
       " 'free',\n",
       " 'doesnt',\n",
       " 'world',\n",
       " 'wasnt',\n",
       " 'new',\n",
       " 'recommend',\n",
       " 'together',\n",
       " 'relationship',\n",
       " 'enjoy',\n",
       " 'felt',\n",
       " 'start',\n",
       " 'next',\n",
       " 'word',\n",
       " 'main',\n",
       " 'put',\n",
       " 'best',\n",
       " 'since',\n",
       " 'looking',\n",
       " 'guy',\n",
       " 'fun',\n",
       " 'real',\n",
       " 'hard',\n",
       " 'long',\n",
       " 'however',\n",
       " 'line',\n",
       " 'sure',\n",
       " 'ive',\n",
       " 'right',\n",
       " 'point',\n",
       " 'day',\n",
       " 'couldnt',\n",
       " 'different',\n",
       " 'shes',\n",
       " 'without',\n",
       " 'family',\n",
       " 'nothing',\n",
       " 'anything',\n",
       " 'ending',\n",
       " 'wanted',\n",
       " 'every',\n",
       " 'help',\n",
       " 'actually',\n",
       " 'he',\n",
       " 'ever',\n",
       " 'worth',\n",
       " 'always',\n",
       " 'men',\n",
       " 'definitely',\n",
       " 'look',\n",
       " 'heroine',\n",
       " 'pretty',\n",
       " 'three',\n",
       " 'action',\n",
       " 'quite',\n",
       " 'fact',\n",
       " 'hero',\n",
       " 'let',\n",
       " 'idea',\n",
       " 'left',\n",
       " 'seemed',\n",
       " 'whole',\n",
       " 'vampire',\n",
       " 'old',\n",
       " 'try',\n",
       " 'sexy',\n",
       " 'tell',\n",
       " 'place',\n",
       " 'feeling',\n",
       " 'brother',\n",
       " 'second',\n",
       " 'around',\n",
       " 'problem',\n",
       " 'might',\n",
       " 'isnt',\n",
       " 'away',\n",
       " 'someone',\n",
       " 'started',\n",
       " 'mystery',\n",
       " 'far',\n",
       " 'nice',\n",
       " 'may',\n",
       " 'kind',\n",
       " 'getting',\n",
       " 'thats',\n",
       " 'issue',\n",
       " 'chapter',\n",
       " 'novella',\n",
       " 'turn',\n",
       " 'almost',\n",
       " 'done',\n",
       " 'yet',\n",
       " '2',\n",
       " 'set',\n",
       " 'kept',\n",
       " 'others',\n",
       " 'seems',\n",
       " 'tale',\n",
       " 'reason',\n",
       " 'past',\n",
       " 'beginning',\n",
       " 'writer',\n",
       " 'said',\n",
       " 'girl',\n",
       " 'last',\n",
       " 'finish',\n",
       " 'wish',\n",
       " 'trying',\n",
       " 'maybe',\n",
       " 'quick',\n",
       " 'mind',\n",
       " 'everything',\n",
       " 'mate',\n",
       " 'couple',\n",
       " 'believe',\n",
       " 'full',\n",
       " 'father',\n",
       " 'job',\n",
       " 'description',\n",
       " 'strong',\n",
       " 'meet',\n",
       " 'development',\n",
       " 'must',\n",
       " 'fantasy',\n",
       " 'hope',\n",
       " 'least',\n",
       " 'anyone',\n",
       " 'there',\n",
       " 'sweet',\n",
       " 'able',\n",
       " 'night',\n",
       " 'mean',\n",
       " 'fan',\n",
       " 'erotic',\n",
       " 'understand',\n",
       " 'care',\n",
       " 'human',\n",
       " 'wont',\n",
       " 'young',\n",
       " 'although',\n",
       " 'easy',\n",
       " 'forward',\n",
       " 'big',\n",
       " 'fast',\n",
       " 'detail',\n",
       " 'money',\n",
       " 'u',\n",
       " 'happy',\n",
       " 'buy',\n",
       " '3',\n",
       " 'id',\n",
       " 'person',\n",
       " 'especially',\n",
       " 'probably',\n",
       " 'home',\n",
       " 'gave',\n",
       " 'went',\n",
       " 'storyline',\n",
       " 'took',\n",
       " 'show',\n",
       " 'write',\n",
       " 'sense',\n",
       " 'seem',\n",
       " 'child',\n",
       " 'instead',\n",
       " 'disappointed',\n",
       " 'used',\n",
       " 'style',\n",
       " 'wait',\n",
       " 'rest',\n",
       " 'favorite',\n",
       " 'rather',\n",
       " 'interest',\n",
       " 'sexual',\n",
       " 'true',\n",
       " 'given',\n",
       " 'longer',\n",
       " 'case',\n",
       " 'less',\n",
       " 'price',\n",
       " 'heart',\n",
       " 'use',\n",
       " 'knew',\n",
       " 'along',\n",
       " 'wonderful',\n",
       " 'high',\n",
       " 'else',\n",
       " 'male',\n",
       " 'lost',\n",
       " 'female',\n",
       " 'type',\n",
       " 'fall',\n",
       " 'several',\n",
       " 'error',\n",
       " 'twist',\n",
       " 'change',\n",
       " 'alpha',\n",
       " 'wrong',\n",
       " 'either',\n",
       " 'finally',\n",
       " 'came',\n",
       " 'glad',\n",
       " 'told',\n",
       " 'cover',\n",
       " 'developed',\n",
       " 'completely',\n",
       " 'making',\n",
       " '5',\n",
       " 'order',\n",
       " 'light',\n",
       " 'stop',\n",
       " 'husband',\n",
       " 'overall',\n",
       " 'enjoyable',\n",
       " '1',\n",
       " 'quickly',\n",
       " 'perfect',\n",
       " 'later',\n",
       " 'lead',\n",
       " 'happened',\n",
       " 'course',\n",
       " 'm',\n",
       " 'side',\n",
       " 'half',\n",
       " 'ok',\n",
       " 'name',\n",
       " 'youre',\n",
       " 'interested',\n",
       " 'wolf',\n",
       " 'happens',\n",
       " '4',\n",
       " 'entire',\n",
       " 'waste',\n",
       " 'fiction',\n",
       " 'everyone',\n",
       " 'become',\n",
       " 'attention',\n",
       " 'already',\n",
       " 'ill',\n",
       " 'sister',\n",
       " 'wife',\n",
       " 'werewolf',\n",
       " 'finished',\n",
       " 'future',\n",
       " 'amazon',\n",
       " 'bought',\n",
       " 'situation',\n",
       " 'believable',\n",
       " 'premise',\n",
       " 'happen',\n",
       " 'wouldnt',\n",
       " 'okay',\n",
       " 'needed',\n",
       " 'truly',\n",
       " 'call',\n",
       " 'mother',\n",
       " 'boring',\n",
       " 'sometimes',\n",
       " 'lover',\n",
       " 'paranormal',\n",
       " 'funny',\n",
       " 'genre',\n",
       " 'ended',\n",
       " 'steamy',\n",
       " 'town',\n",
       " 'eye',\n",
       " 'boy',\n",
       " 'dialogue',\n",
       " 'guess',\n",
       " 'length',\n",
       " 'highly',\n",
       " 'chance',\n",
       " 'war',\n",
       " 'lack',\n",
       " 'thinking',\n",
       " 'moment',\n",
       " 'entertaining',\n",
       " 'live',\n",
       " 'version',\n",
       " 'sort',\n",
       " 'pack',\n",
       " 'house',\n",
       " 'romantic',\n",
       " 'add',\n",
       " 'dark',\n",
       " 'leave',\n",
       " 'totally',\n",
       " 'title',\n",
       " 'language',\n",
       " 'usually',\n",
       " 'head',\n",
       " 'follow',\n",
       " 'age',\n",
       " 'editing',\n",
       " 'move',\n",
       " 'school',\n",
       " 'sorry',\n",
       " 'reviewer',\n",
       " 'stand',\n",
       " 'pick',\n",
       " 'coming',\n",
       " 'hand',\n",
       " 'yes',\n",
       " 'throughout',\n",
       " 'run',\n",
       " 'secret',\n",
       " 'potential',\n",
       " 'experience',\n",
       " 'expect',\n",
       " 'ago',\n",
       " 'depth',\n",
       " 'begin',\n",
       " 'simply',\n",
       " 'figure',\n",
       " 'soon',\n",
       " 'expected',\n",
       " 'death',\n",
       " 'deal',\n",
       " 'absolutely',\n",
       " 'dream',\n",
       " 'decided',\n",
       " 'adult',\n",
       " 'h',\n",
       " 'turned',\n",
       " 'wanting',\n",
       " 'oh',\n",
       " 'called',\n",
       " 'unfortunately',\n",
       " 'month',\n",
       " 'save',\n",
       " 'theyre',\n",
       " 'giving',\n",
       " 'history',\n",
       " 'often',\n",
       " 'matter',\n",
       " 'poor',\n",
       " 'small',\n",
       " 'erotica',\n",
       " 'collection',\n",
       " 'alone',\n",
       " 'hour',\n",
       " 'difficult',\n",
       " 'humor',\n",
       " 'event',\n",
       " 'top',\n",
       " 'hate',\n",
       " 'certainly',\n",
       " 'movie',\n",
       " 'face',\n",
       " 'spent',\n",
       " 'third',\n",
       " 'four',\n",
       " 'complete',\n",
       " 'hold',\n",
       " 'setting',\n",
       " 'missing',\n",
       " 'excellent',\n",
       " 'soul',\n",
       " 'rating',\n",
       " 'kill',\n",
       " 'easily',\n",
       " 'stay',\n",
       " 'bed',\n",
       " 'adventure',\n",
       " 'dragon',\n",
       " 'emotion',\n",
       " 'talk',\n",
       " 'supposed',\n",
       " 'slow',\n",
       " 'attraction',\n",
       " 'across',\n",
       " 'five',\n",
       " 'involved',\n",
       " 'sentence',\n",
       " 'opinion',\n",
       " 'god',\n",
       " 'surprise',\n",
       " 'cute',\n",
       " 'learn',\n",
       " 'information',\n",
       " 'group',\n",
       " 'question',\n",
       " 'marriage',\n",
       " 'shifter',\n",
       " 'killer',\n",
       " 'married',\n",
       " 'list',\n",
       " 'living',\n",
       " 'fight',\n",
       " 'background',\n",
       " 'finding',\n",
       " 'tried',\n",
       " 'continue',\n",
       " 'murder',\n",
       " 'play',\n",
       " 'son',\n",
       " 'kid',\n",
       " 'break',\n",
       " 'gay',\n",
       " 'perhaps',\n",
       " 'realize',\n",
       " 'based',\n",
       " 'power',\n",
       " 'extremely',\n",
       " 'suspense',\n",
       " 'predictable',\n",
       " 'plan',\n",
       " 'example',\n",
       " 'taking',\n",
       " 'beautiful',\n",
       " 'met',\n",
       " 'amazing',\n",
       " 'surprised',\n",
       " 'waiting',\n",
       " 'middle',\n",
       " 'seen',\n",
       " 'daughter',\n",
       " 'behind',\n",
       " 'within',\n",
       " 'pay',\n",
       " 'level',\n",
       " 'beyond',\n",
       " 'hell',\n",
       " 'mr',\n",
       " 'became',\n",
       " 'desire',\n",
       " 'remember',\n",
       " 'aspect',\n",
       " 'known',\n",
       " 'saying',\n",
       " 'minute',\n",
       " 'body',\n",
       " 'room',\n",
       " 'content',\n",
       " 'youll',\n",
       " 'working',\n",
       " 'loving',\n",
       " 'heat',\n",
       " 'form',\n",
       " 'etc',\n",
       " 'mark',\n",
       " 'taken',\n",
       " 'early',\n",
       " 'week',\n",
       " 'magic',\n",
       " 'immediately',\n",
       " 'concept',\n",
       " 'force',\n",
       " 'seeing',\n",
       " 'emotional',\n",
       " 'saw',\n",
       " 'fit',\n",
       " 'downloaded',\n",
       " 'due',\n",
       " 'willing',\n",
       " 'open',\n",
       " 'lady',\n",
       " 'trouble',\n",
       " 'admit',\n",
       " 'view',\n",
       " 'original',\n",
       " 'number',\n",
       " 'brought',\n",
       " 'fell',\n",
       " 'share',\n",
       " 'close',\n",
       " 'mistake',\n",
       " 'hoping',\n",
       " 'paid',\n",
       " 'hunter',\n",
       " 'business',\n",
       " 'huge',\n",
       " 'previous',\n",
       " 'editor',\n",
       " 'spoiler',\n",
       " 'stuff',\n",
       " 'special',\n",
       " 'connection',\n",
       " 'seriously',\n",
       " 'check',\n",
       " 'tension',\n",
       " 'picture',\n",
       " 'exactly',\n",
       " 'alex',\n",
       " 'science',\n",
       " 'mostly',\n",
       " 'bring',\n",
       " 'note',\n",
       " 'somewhat',\n",
       " 'using',\n",
       " 'choice',\n",
       " 'chemistry',\n",
       " 'important',\n",
       " 'christmas',\n",
       " 'ready',\n",
       " 'cannot',\n",
       " 'simple',\n",
       " 'havent',\n",
       " 'sequel',\n",
       " 'drawn',\n",
       " 'space',\n",
       " 'leaf',\n",
       " 'dead',\n",
       " 'forced',\n",
       " 'decides',\n",
       " 'building',\n",
       " 'arent',\n",
       " 'taste',\n",
       " 'except',\n",
       " 'demon',\n",
       " 'james',\n",
       " 'fine',\n",
       " 'expecting',\n",
       " 'mention',\n",
       " 'quality',\n",
       " 'ability',\n",
       " 'wonder',\n",
       " 'clear',\n",
       " 'unique',\n",
       " 'becomes',\n",
       " 'element',\n",
       " 'return',\n",
       " 'bother',\n",
       " 'decent',\n",
       " 'exciting',\n",
       " 'serious',\n",
       " 'older',\n",
       " 'telling',\n",
       " 'download',\n",
       " 'black',\n",
       " 'reviewed',\n",
       " 'spend',\n",
       " 'graphic',\n",
       " 'please',\n",
       " 'partner',\n",
       " 'piece',\n",
       " 'despite',\n",
       " 'zombie',\n",
       " 'flow',\n",
       " 'bdsm',\n",
       " 'fairly',\n",
       " 'filled',\n",
       " 'serial',\n",
       " 'described',\n",
       " 'annoying',\n",
       " 'passion',\n",
       " 'agree',\n",
       " 'christian',\n",
       " 'caught',\n",
       " 'picked',\n",
       " 'strange',\n",
       " 'horror',\n",
       " 'evil',\n",
       " 'parent',\n",
       " 'personal',\n",
       " 'none',\n",
       " 'hurt',\n",
       " 'realistic',\n",
       " 'fairy',\n",
       " 'police',\n",
       " 'ebook',\n",
       " 'trust',\n",
       " 'fear',\n",
       " 'mentioned',\n",
       " 'upon',\n",
       " 'offer',\n",
       " 'conflict',\n",
       " 'plus',\n",
       " 'including',\n",
       " 'rushed',\n",
       " 'scifi',\n",
       " 'particularly',\n",
       " 'present',\n",
       " 'weak',\n",
       " 'added',\n",
       " 'gone',\n",
       " 'worked',\n",
       " 'ghost',\n",
       " 'writes',\n",
       " 'lose',\n",
       " 'accept',\n",
       " 'grammar',\n",
       " 'basically',\n",
       " 'stupid',\n",
       " 'copy',\n",
       " 'menage',\n",
       " 'major',\n",
       " 'honest',\n",
       " 'protagonist',\n",
       " 'straight',\n",
       " 'purchase',\n",
       " 'typo',\n",
       " 'neither',\n",
       " 'classic',\n",
       " 'car',\n",
       " 'certain',\n",
       " 'earth',\n",
       " 'knowing',\n",
       " 'historical',\n",
       " 'confusing',\n",
       " 'basic',\n",
       " 'sad',\n",
       " 'fully',\n",
       " 'thrown',\n",
       " 'club',\n",
       " 'whether',\n",
       " 'hit',\n",
       " 'held',\n",
       " 'crazy',\n",
       " 'poorly',\n",
       " 'personality',\n",
       " 'purchased',\n",
       " 'kate',\n",
       " 'intriguing',\n",
       " 'sound',\n",
       " 'single',\n",
       " 'touch',\n",
       " 'amount',\n",
       " 'date',\n",
       " 'attempt',\n",
       " 'build',\n",
       " 'paragraph',\n",
       " 'suddenly',\n",
       " 'marry',\n",
       " 'imagine',\n",
       " 'act',\n",
       " 'max',\n",
       " 'nature',\n",
       " 'struggle',\n",
       " 'promise',\n",
       " 'meeting',\n",
       " 'thriller',\n",
       " 'honestly',\n",
       " 'control',\n",
       " 'simon',\n",
       " 'alien',\n",
       " 'term',\n",
       " 'normally',\n",
       " 'available',\n",
       " 'blog',\n",
       " 'effort',\n",
       " 'fighting',\n",
       " 'game',\n",
       " 'awesome',\n",
       " 'baby',\n",
       " 'kelly',\n",
       " 'unless',\n",
       " 'john',\n",
       " 'boyfriend',\n",
       " 'thank',\n",
       " 'ridiculous',\n",
       " 'blood',\n",
       " 'hooked',\n",
       " 'lord',\n",
       " 'buying',\n",
       " 'whats',\n",
       " 'worst',\n",
       " 'theme',\n",
       " '10',\n",
       " 'drama',\n",
       " 'prequel',\n",
       " 'paper',\n",
       " 'wedding',\n",
       " 'super',\n",
       " 'king',\n",
       " 'master',\n",
       " 'blake',\n",
       " 'determined',\n",
       " 'conversation',\n",
       " 'actual',\n",
       " 'fantastic',\n",
       " 'wrote',\n",
       " 'flat',\n",
       " 'introduced',\n",
       " 'joyfully',\n",
       " 'horrible',\n",
       " 'deep',\n",
       " 'develop',\n",
       " 'focus',\n",
       " 'typical',\n",
       " 'trilogy',\n",
       " 'otherwise',\n",
       " 'talking',\n",
       " 'area',\n",
       " 'knight',\n",
       " 'apparently',\n",
       " 'edge',\n",
       " 'miss',\n",
       " 'belief',\n",
       " 'self',\n",
       " 'created',\n",
       " 'jane',\n",
       " 'modern',\n",
       " 'possible',\n",
       " 'turning',\n",
       " 'leaving',\n",
       " 'thoroughly',\n",
       " 'pas',\n",
       " 'encounter',\n",
       " 'truth',\n",
       " 'escape',\n",
       " 'company',\n",
       " 'recommended',\n",
       " 'afraid',\n",
       " 'near',\n",
       " 'published',\n",
       " 'reality',\n",
       " 'protect',\n",
       " 'stopped',\n",
       " 'edition',\n",
       " 'sample',\n",
       " 'interaction',\n",
       " 'explanation',\n",
       " 'worse',\n",
       " 'cause',\n",
       " 'danger',\n",
       " 'moving',\n",
       " 'animal',\n",
       " 'decision',\n",
       " 'silly',\n",
       " 'confused',\n",
       " 'disappointing',\n",
       " 'moved',\n",
       " 'odd',\n",
       " 'cut',\n",
       " 'unbelievable',\n",
       " 'pleasure',\n",
       " 'grab',\n",
       " 'satisfying',\n",
       " 'wow',\n",
       " 'jump',\n",
       " 'jack',\n",
       " 'party',\n",
       " '99',\n",
       " 'werent',\n",
       " 'pull',\n",
       " 'paced',\n",
       " 'cat',\n",
       " 'looked',\n",
       " 'magazine',\n",
       " 'throw',\n",
       " 'changed',\n",
       " 'voice',\n",
       " 'period',\n",
       " 'subject',\n",
       " 'engaging',\n",
       " 'particular',\n",
       " 'pace',\n",
       " 'realized',\n",
       " 'product',\n",
       " 'happily',\n",
       " 'decide',\n",
       " 'jake',\n",
       " 'draw',\n",
       " 'plenty',\n",
       " 'owner',\n",
       " 'wondering',\n",
       " 'difference',\n",
       " 'answer',\n",
       " 'laugh',\n",
       " 'article',\n",
       " 'us',\n",
       " 'reread',\n",
       " 'watching',\n",
       " 'falling',\n",
       " 'red',\n",
       " 'ask',\n",
       " 'pain',\n",
       " 'inside',\n",
       " 'angel',\n",
       " 'running',\n",
       " 'english',\n",
       " 'familiar',\n",
       " 'final',\n",
       " 'literally',\n",
       " 'violence',\n",
       " 'ship',\n",
       " 'battle',\n",
       " 'lust',\n",
       " 'similar',\n",
       " 'beauty',\n",
       " 'role',\n",
       " 'obviously',\n",
       " 'anyway',\n",
       " 'towards',\n",
       " 'missed',\n",
       " 'consider',\n",
       " 'terrible',\n",
       " 'ex',\n",
       " 'american',\n",
       " 'trip',\n",
       " 'introduction',\n",
       " 'killed',\n",
       " 'weird',\n",
       " 'lacking',\n",
       " 'starting',\n",
       " 'detective',\n",
       " 'journey',\n",
       " 'society',\n",
       " 'current',\n",
       " 'fire',\n",
       " 'crime',\n",
       " 'yeah',\n",
       " 'bored',\n",
       " 'nearly',\n",
       " 'killing',\n",
       " 'appreciate',\n",
       " 'member',\n",
       " 'state',\n",
       " 'skip',\n",
       " 'conclusion',\n",
       " 'keeping',\n",
       " 'rape',\n",
       " 'mysterious',\n",
       " 'warning',\n",
       " 'comment',\n",
       " 'realizes',\n",
       " 'slave',\n",
       " 'reference',\n",
       " 'henry',\n",
       " 'city',\n",
       " 'explained',\n",
       " 'cop',\n",
       " 'rich',\n",
       " 'team',\n",
       " 'step',\n",
       " 'eventually',\n",
       " 'emma',\n",
       " 'outside',\n",
       " 'door',\n",
       " 'explicit',\n",
       " 'travel',\n",
       " 'country',\n",
       " 'claim',\n",
       " 'attracted',\n",
       " 'bond',\n",
       " 'included',\n",
       " 'college',\n",
       " 'received',\n",
       " 'imagination',\n",
       " 'enjoying',\n",
       " 'research',\n",
       " 'apart',\n",
       " 'today',\n",
       " 'obvious',\n",
       " 'allow',\n",
       " 'location',\n",
       " 'meant',\n",
       " 'brings',\n",
       " 'barely',\n",
       " 'doubt',\n",
       " 'speak',\n",
       " 'attack',\n",
       " 'hea',\n",
       " 'complaint',\n",
       " 'normal',\n",
       " 'smart',\n",
       " 'result',\n",
       " 'hadnt',\n",
       " 'slightly',\n",
       " 'island',\n",
       " 'freebie',\n",
       " 'cold',\n",
       " 'law',\n",
       " '6',\n",
       " 'late',\n",
       " 'awful',\n",
       " 'west',\n",
       " 'count',\n",
       " 'solid',\n",
       " 'win',\n",
       " 'mm',\n",
       " 'land',\n",
       " 'lived',\n",
       " 'bell',\n",
       " 'wild',\n",
       " 'news',\n",
       " 'continues',\n",
       " 'whose',\n",
       " 'holly',\n",
       " 'teenager',\n",
       " 'purpose',\n",
       " 'rough',\n",
       " 'teen',\n",
       " 'cousin',\n",
       " 'verne',\n",
       " 'military',\n",
       " 'formatting',\n",
       " 'rachel',\n",
       " 'magical',\n",
       " 'witch',\n",
       " 'catch',\n",
       " 'cole',\n",
       " 'nicely',\n",
       " 'watch',\n",
       " 'installment',\n",
       " 'whatever',\n",
       " 'likeable',\n",
       " 'physical',\n",
       " 'mating',\n",
       " 'forever',\n",
       " 'safe',\n",
       " 'sight',\n",
       " 'likable',\n",
       " 'intense',\n",
       " 'leader',\n",
       " 'following',\n",
       " 'constantly',\n",
       " 'usual',\n",
       " 'detailed',\n",
       " 'personally',\n",
       " 'kiss',\n",
       " 'survive',\n",
       " ...]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "69422aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "54898d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8158"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fa259493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "690a4651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.9023233652114868),\n",
       " ('potential', 0.89444899559021),\n",
       " ('easy', 0.8912692070007324),\n",
       " ('overall', 0.8908536434173584),\n",
       " ('ok', 0.8884605169296265),\n",
       " ('cute', 0.8877103328704834),\n",
       " ('nice', 0.887262761592865),\n",
       " ('okay', 0.8847057819366455),\n",
       " ('predictable', 0.8758370876312256),\n",
       " ('line', 0.8753783702850342)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f8d8a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['good'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "77a3f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b334f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    vector=[model.wv[word] for word in doc if word in model.wv.index_to_key]\n",
    "    return np.mean(vector,axis=0) if vector else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d8d815f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e6287873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9600/9600 [00:09<00:00, 1003.25it/s]\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for i in tqdm(range(len(sent_train))):\n",
    "    X.append(avg_word2vec(sent_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ffe9b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_test=X_test_wv.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "57db01cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2400/2400 [00:02<00:00, 999.45it/s] \n"
     ]
    }
   ],
   "source": [
    "def avg_word2vec(doc):\n",
    "    vector=[model.wv[word] for word in doc if word in model.wv.index_to_key]\n",
    "    return np.mean(vector,axis=0) if vector else np.zeros(model.vector_size)\n",
    "\n",
    "X_test_wv_new=[]\n",
    "for i in tqdm(range(len(sent_test))):\n",
    "    X_test_wv_new.append(avg_word2vec(sent_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_wv_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9093fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wv_new_array=np.array(X_test_wv_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20676365, -0.26643732, -0.22324198, ..., -0.2311376 ,\n",
       "         0.35348883, -0.14576113],\n",
       "       [ 0.28371623, -0.5494031 , -0.3096563 , ..., -0.3276717 ,\n",
       "         0.5975193 , -0.1930627 ],\n",
       "       [ 0.18036748, -0.2138523 , -0.33867547, ..., -0.27379045,\n",
       "         0.36532056, -0.25732622],\n",
       "       ...,\n",
       "       [ 0.2659359 , -0.32161182, -0.4585664 , ..., -0.28378585,\n",
       "         0.441979  , -0.31837928],\n",
       "       [ 0.31814513, -0.40092686, -0.2663423 , ..., -0.20204131,\n",
       "         0.3442757 , -0.14699864],\n",
       "       [ 0.20327987, -0.39575756, -0.29414743, ..., -0.36257437,\n",
       "         0.46175563, -0.22990862]], dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_wv_new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6d44c3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_wv_new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cfd8cb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f533a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d448c408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 150)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ee5c8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600,)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ff24df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_w2v=GaussianNB().fit(X_new,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "833179d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_w2v=nb_w2v.predict(X_test_wv_new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f500e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "78b3fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.58875\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score\",accuracy_score(y_test,y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "94bc06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27       799\n",
      "           1       0.67      0.77      0.71      1601\n",
      "\n",
      "    accuracy                           0.59      2400\n",
      "   macro avg       0.50      0.50      0.49      2400\n",
      "weighted avg       0.55      0.59      0.56      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\",classification_report(y_test,y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "32170f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix [[ 178  621]\n",
      " [ 366 1235]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion_matrix\",confusion_matrix(y_test,y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "deb8ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_test,y_pred_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6ea41233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7144923343939832\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
